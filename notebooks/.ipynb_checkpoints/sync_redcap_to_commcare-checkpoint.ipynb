{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync REDCap To CommCare \n",
    "\n",
    "A playground for testing `sync_redcap_to_commcare.py` and its utilities in `redcap_sync.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import redcap\n",
    "\n",
    "from cc_utilities.command_line.sync_redcap_to_commcare import get_redcap_state\n",
    "from cc_utilities.redcap_sync import (\n",
    "    collapse_checkbox_columns,\n",
    "    normalize_phone_cols,\n",
    "    set_external_id_column,\n",
    "    upload_complete_records,\n",
    "    upload_incomplete_records,\n",
    "    split_complete_and_incomplete_records,\n",
    "    add_integration_status_columns,\n",
    "    import_records_to_redcap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "redcap_api_url = os.getenv(\"REDCAP_API_URL\")\n",
    "redcap_api_key = os.getenv(\"REDCAP_API_KEY\")\n",
    "commcare_api_key = os.getenv(\"COMMCARE_API_KEY\")\n",
    "commcare_user_name = os.getenv(\"COMMCARE_USERNAME\")\n",
    "commcare_project_name = os.getenv(\"COMMCARE_PROJECT\")\n",
    "database_url = os.getenv(\"DB_URL\")\n",
    "\n",
    "state_file = \"redcap_test.yaml\"\n",
    "sync_all = True\n",
    "phone_cols = []\n",
    "external_id_col = \"cdms_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get REDCap records\n",
    "\n",
    "state = get_redcap_state(state_file)\n",
    "redcap_project = redcap.Project(redcap_api_url, redcap_api_key)\n",
    "redcap_records = redcap_project.export_records(\n",
    "    # Tell PyCap to return a pandas DataFrame.\n",
    "    format=\"df\",\n",
    "    df_kwargs={\n",
    "        # Without index_col=False, read_csv() will use the first column\n",
    "        # (\"record_id\") as the index, which is problematic because it's\n",
    "        # not unique and is easier to handle as a separate column anyways.\n",
    "        \"index_col\": False,\n",
    "        # We import everything as a string, to avoid pandas coercing ints\n",
    "        # to floats and adding unnecessary decimal points in the data when\n",
    "        # uploaded to CommCare.\n",
    "        \"dtype\": str,\n",
    "    },\n",
    "#     filter_logic=\"[integration_status] = ''\",\n",
    ")\n",
    "\n",
    "redcap_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Records in CDMS\n",
    "\n",
    "For testing what's inside `match_records_in_cdms()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sqlalchemy import MetaData, Table, and_, create_engine, select, or_\n",
    "from cc_utilities.constants import DOB_FIELD\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "external_id = redcap_records[\"cdms_id\"][0]\n",
    "dob = redcap_records[\"dob\"][0]\n",
    "\n",
    "external_id_col = \"cdms_id\"\n",
    "db_url = database_url\n",
    "table_name = \"patient\"\n",
    "\n",
    "print(f\"CDMS_ID: {external_id},\\nDOB: {dob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows missing DOB or External ID\n",
    "df = redcap_records.dropna(subset=[external_id_col, DOB_FIELD])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table\n",
    "engine = create_engine(db_url)\n",
    "meta = MetaData(bind=engine)\n",
    "table = Table(table_name, meta, autoload=True, autoload_with=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate columns\n",
    "column_names = [col.name for col in table.columns]\n",
    "assert DOB_FIELD in column_names, \\\n",
    "    f\"{DOB_FIELD} not in {table_name} table\"\n",
    "assert external_id_col in column_names, \\\n",
    "    f\"{external_id_col} not in {table_name} table\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query\n",
    "wheres = []\n",
    "for record in df.itertuples():\n",
    "    dob = record.dob\n",
    "    external_id = getattr(record, external_id_col)\n",
    "    print(f\"Processing dob {dob} and id {external_id}\")\n",
    "    wheres.append([\n",
    "        getattr(table.c, external_id_col) == external_id,\n",
    "        getattr(table.c, DOB_FIELD) == dob\n",
    "    ])\n",
    "\n",
    "query = select(\n",
    "    [getattr(table.c, external_id_col), \n",
    "     getattr(table.c, DOB_FIELD)]\n",
    ")\n",
    "# .where(\n",
    "#     or_(*[and_(*where) for where in wheres])\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "conn = engine.connect()\n",
    "try:\n",
    "    result = conn.execute(query)\n",
    "    matching_records = [dict(row) for row in result.fetchall()]\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "pprint(\"Got matches for: \")\n",
    "pprint(matching_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Records to matched/unmatched. \n",
    "matched_external_ids = [m[external_id_col] for m in matching_records]\n",
    "unmatched_records = df.where(~df[external_id_col].isin(matched_external_ids)).dropna(subset=[external_id_col])[[\"record_id\"]]\n",
    "matched_records = df.where(df[external_id_col].isin(matched_external_ids)).dropna(subset=[external_id_col])\n",
    "\n",
    "matched_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_records = add_reject_status_columns(unmatched_records, external_id_col).dropna(axis=1)\n",
    "reject_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDCap Import\n",
    "\n",
    "redcap_project = redcap.Project(redcap_api_url, redcap_api_key)\n",
    "response = redcap_project.import_records(\n",
    "    to_import=reject_records,\n",
    "    overwrite=\"normal\",\n",
    "    return_content=\"ids\",\n",
    ")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cases_df = normalize_phone_cols(redcap_records, phone_cols)\n",
    "cases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_df = set_external_id_column(cases_df, external_id_col)\n",
    "cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From split_complete_and_incomplete_records\n",
    "# Drop columns where all values are missing.\n",
    "cases_df = cases_df.dropna(axis=1, how=\"all\")\n",
    "cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_records, incomplete_records = split_complete_and_incomplete_records(cases_df)\n",
    "complete_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.concat([complete_records, incomplete_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# upload_complete_records(\n",
    "#     cases_df, commcare_api_key, commcare_project_name, commcare_user_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# upload_incomplete_records(\n",
    "#     cases_df, commcare_api_key, commcare_project_name, commcare_user_name\n",
    "# )\n",
    "\n",
    "for index, row in incomplete_records.iterrows():\n",
    "    # Drops any values in this Series with missing/NA values,\n",
    "    # and converts it back to a DataFrame.\n",
    "    data = row.dropna().to_frame().transpose()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
